{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing the neccesary libraries"
      ],
      "metadata": {
        "id": "GmbhggzvMg9i"
      },
      "id": "GmbhggzvMg9i"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "aGy9yRVGNWIe"
      },
      "id": "aGy9yRVGNWIe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0be4a8e-d2c9-4813-9355-4b41f5562bd7",
      "metadata": {
        "id": "f0be4a8e-d2c9-4813-9355-4b41f5562bd7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from transformers import VivitImageProcessor, VivitForVideoClassification\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "import copy\n",
        "image_processor = VivitImageProcessor.from_pretrained(\"google/vivit-b-16x2-kinetics400\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Loading"
      ],
      "metadata": {
        "id": "tZU1rTii2i-6"
      },
      "id": "tZU1rTii2i-6"
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 99"
      ],
      "metadata": {
        "id": "HGioJBX8ieWk"
      },
      "id": "HGioJBX8ieWk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f017cbc-d897-4c7f-8f25-b9fdf1f7b6e1",
      "metadata": {
        "id": "2f017cbc-d897-4c7f-8f25-b9fdf1f7b6e1"
      },
      "outputs": [],
      "source": [
        "def build_model(fine_tune = False):\n",
        "    model = VivitForVideoClassification.from_pretrained(\"google/vivit-b-16x2-kinetics400\")\n",
        "    if fine_tune:\n",
        "        print('[INFO]: Fine-tuning all layers...')\n",
        "        for params in model.parameters():\n",
        "            params.requires_grad = True\n",
        "    if not fine_tune:\n",
        "        print('[INFO]: Freezing hidden layers...')\n",
        "        for params in model.parameters():\n",
        "            params.requires_grad = False\n",
        "\n",
        "    num_features = model.classifier.in_features\n",
        "    model.classifier = nn.Linear(num_features, num_classes)\n",
        "    return model\n",
        "\n",
        "model = build_model(False)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Freezing the parameters not needed for training\n",
        "\n",
        "cnt = 1\n",
        "for params in model.parameters():\n",
        "\n",
        "    if cnt <= 198:\n",
        "        params.requires_grad = False\n",
        "    else:\n",
        "        params.requires_grad = True\n",
        "\n",
        "    cnt += 1"
      ],
      "metadata": {
        "id": "uknLAhDHrbiZ"
      },
      "id": "uknLAhDHrbiZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c629b07-f6b0-40de-99bf-b5dc5428014e",
      "metadata": {
        "id": "0c629b07-f6b0-40de-99bf-b5dc5428014e"
      },
      "outputs": [],
      "source": [
        "# Verifying which parameters are frozen\n",
        "\n",
        "cnt = 1\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "\n",
        "    print(f'{cnt}: {name}: {\"Trainable\" if param.requires_grad else \"Frozen\"}')\n",
        "\n",
        "    cnt+=1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Loading"
      ],
      "metadata": {
        "id": "UrmeGnspNLdg"
      },
      "id": "UrmeGnspNLdg"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41e7f63d-3ec6-4662-a05a-bc58dd070734",
      "metadata": {
        "id": "41e7f63d-3ec6-4662-a05a-bc58dd070734"
      },
      "outputs": [],
      "source": [
        "# Loading the datasets stored as binary numpy files\n",
        "train_videos = np.load(\"/content/drive/MyDrive/AI Masters final project/data_32_80_80_3_no_0/train_data.npy\")\n",
        "valid_videos = np.load(\"/content/drive/MyDrive/AI Masters final project/data_32_80_80_3_no_0/val_data.npy\")\n",
        "test_videos = np.load(\"/content/drive/MyDrive/AI Masters final project/data_32_80_80_3_no_0/test_data.npy\")\n",
        "\n",
        "train_labels = np.load(\"/content/drive/MyDrive/AI Masters final project/data_32_80_80_3_no_0/train_label.npy\")\n",
        "valid_labels = np.load(\"/content/drive/MyDrive/AI Masters final project/data_32_80_80_3_no_0/val_label.npy\")\n",
        "test_labels = np.load(\"/content/drive/MyDrive/AI Masters final project/data_32_80_80_3_no_0/test_label.npy\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 8"
      ],
      "metadata": {
        "id": "CGeuKdruu7OT"
      },
      "id": "CGeuKdruu7OT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining a custom dataset class which inherits from torch.utils.data.Dataset\n",
        "class CustomVideoDataset(Dataset):\n",
        "    def __init__(self, video_files, labels, transform=None):\n",
        "        self.video_files = video_files\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.video_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        video = self.video_files[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            video = self.transform(video)\n",
        "\n",
        "        # Convert video and label to PyTorch tensors\n",
        "        video = image_processor(list(video))\n",
        "        video = torch.tensor(video['pixel_values'][0], dtype=torch.float32)\n",
        "        label = torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "        return video, label"
      ],
      "metadata": {
        "id": "DJv248c3GSPO"
      },
      "id": "DJv248c3GSPO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22753b92-66ad-499b-a13d-3ae4b466a3c6",
      "metadata": {
        "id": "22753b92-66ad-499b-a13d-3ae4b466a3c6"
      },
      "outputs": [],
      "source": [
        "# Create dataset and dataloader for training data\n",
        "train_dataset = CustomVideoDataset(train_videos, train_labels)\n",
        "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Iterate over the dataloader\n",
        "for batch_videos, batch_labels in trainloader:\n",
        "    print(type(batch_videos))\n",
        "    print(f\"Batch videos shape: {batch_videos.shape}\")\n",
        "    print(f\"Batch labels shape: {batch_labels.shape}\")\n",
        "    break  # Just to show the shape for one batch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dataset and dataloader for validation data\n",
        "valid_dataset = CustomVideoDataset(valid_videos, valid_labels)\n",
        "validloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Iterate over the dataloader\n",
        "for batch_videos, batch_labels in validloader:\n",
        "    print(type(batch_videos))\n",
        "    print(f\"Batch videos shape: {batch_videos.shape}\")\n",
        "    print(f\"Batch labels shape: {batch_labels.shape}\")\n",
        "    break  # Just to show the shape for one batch"
      ],
      "metadata": {
        "id": "TAcz836oR3iA"
      },
      "id": "TAcz836oR3iA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dataset and dataloader for testing data\n",
        "test_dataset = CustomVideoDataset(test_videos, test_labels)\n",
        "testloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Iterate over the dataloader\n",
        "for batch_videos, batch_labels in testloader:\n",
        "    print(type(batch_videos))\n",
        "    print(f\"Batch videos shape: {batch_videos.shape}\")\n",
        "    print(f\"Batch labels shape: {batch_labels.shape}\")\n",
        "    break  # Just to show the shape for one batch"
      ],
      "metadata": {
        "id": "od2fdsoV5_di"
      },
      "id": "od2fdsoV5_di",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment 1\n",
        "\n",
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "g-n1USdo-q7N"
      },
      "id": "g-n1USdo-q7N"
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "HCdfGGTFJRk_"
      },
      "id": "HCdfGGTFJRk_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_accuracy_epoch = []\n",
        "train_loss_epoch = []\n",
        "\n",
        "val_accuracy_epoch = []\n",
        "val_loss_epoch = []"
      ],
      "metadata": {
        "id": "F5ssY9R5-2yB"
      },
      "id": "F5ssY9R5-2yB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize Variables for EarlyStopping\n",
        "best_loss = float('inf')\n",
        "best_model_weights = None\n",
        "patience = 3\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "my_lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, patience = patience)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "num_epochs = 15\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "model.to(device)\n",
        "\n",
        "train_accuracy_epoch = []\n",
        "train_loss_epoch = []\n",
        "\n",
        "val_accuracy_epoch = []\n",
        "val_loss_epoch = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    train_running_loss = 0.0\n",
        "    train_running_correct = 0\n",
        "    train_bs_accumuator = 0\n",
        "\n",
        "    valid_running_loss = 0.0\n",
        "    valid_running_correct = 0\n",
        "    valid_bs_accumuator = 0\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    # Training Loop\n",
        "    for videos, labels in tqdm(trainloader):\n",
        "\n",
        "        videos, labels = videos.to(device), labels.to(device)\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(videos)\n",
        "\n",
        "        logits = outputs.logits\n",
        "\n",
        "        train_bs_accumuator += logits.shape[0]\n",
        "\n",
        "        # Compute loss\n",
        "        loss = criterion(logits, labels)\n",
        "\n",
        "        # Calculate the accuracy.\n",
        "        _, preds = torch.max(logits, 1)\n",
        "\n",
        "        train_running_correct += (preds == labels).sum().item()\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * videos.size(0)\n",
        "\n",
        "        i += 1\n",
        "\n",
        "    # Validation Loop\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for videos, labels in validloader:\n",
        "\n",
        "            videos, labels = videos.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(videos)\n",
        "\n",
        "            logits = outputs.logits\n",
        "\n",
        "            valid_bs_accumuator += logits.shape[0]\n",
        "\n",
        "            # Compute loss\n",
        "            loss = criterion(logits, labels)\n",
        "\n",
        "            _, preds = torch.max(logits, 1)\n",
        "\n",
        "            valid_running_correct += (preds == labels).sum().item()\n",
        "\n",
        "            valid_running_loss += loss.item() * videos.size(0)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    elapsed_time = end_time - start_time\n",
        "    print(f\"Elapsed time: {elapsed_time} seconds\")\n",
        "\n",
        "    epoch_loss = running_loss / len(trainloader.dataset)\n",
        "    epoch_acc = 100. * (train_running_correct / train_bs_accumuator)\n",
        "\n",
        "    valid_loss = valid_running_loss / len(validloader.dataset)\n",
        "    valid_acc = 100. * (valid_running_correct / valid_bs_accumuator)\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {epoch_loss:.4f}, Training Accuracy: {epoch_acc:.4f}\")\n",
        "\n",
        "    print(f\"Validation Loss: {valid_loss:.4f}, Validation Accuracy: {valid_acc:.4f}\")\n",
        "\n",
        "    train_accuracy_epoch.append(epoch_acc)\n",
        "    train_loss_epoch.append(epoch_loss)\n",
        "\n",
        "    val_accuracy_epoch.append(valid_acc)\n",
        "    val_loss_epoch.append(valid_loss)\n",
        "\n",
        "    my_lr_scheduler.step(valid_loss)\n",
        "\n",
        "    if valid_loss < best_loss:\n",
        "        best_loss = valid_loss\n",
        "        best_model_weights = copy.deepcopy(model.state_dict())\n",
        "        patience = 3\n",
        "    else:\n",
        "        patience -= 1\n",
        "        if patience == 0:\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "model.load_state_dict(best_model_weights)"
      ],
      "metadata": {
        "id": "tjmRcmtU-zNm"
      },
      "id": "tjmRcmtU-zNm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the accuracy curve\n",
        "plt.plot(train_accuracy_epoch)\n",
        "plt.plot(val_accuracy_epoch)\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HdszDpe6jFxl"
      },
      "id": "HdszDpe6jFxl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the loss curve\n",
        "plt.plot(train_loss_epoch)\n",
        "plt.plot(val_loss_epoch)\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6eVV8ibEjMOp"
      },
      "id": "6eVV8ibEjMOp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, \"/content/drive/MyDrive/AI Masters final project/data_32_80_80_3_no_0/model_7.pth\")"
      ],
      "metadata": {
        "id": "z5XEPQXqi7DF"
      },
      "id": "z5XEPQXqi7DF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Running the model on the test dataset\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "test_running_correct = 0\n",
        "test_bs_accumuator = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in tqdm(testloader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "\n",
        "        logits = outputs.logits\n",
        "        test_bs_accumuator += logits.shape[0]\n",
        "\n",
        "        _, preds = torch.max(logits, 1)\n",
        "        test_running_correct += (preds == labels).sum().item()\n",
        "\n",
        "test_accuracy = 100. * test_running_correct / test_bs_accumuator\n",
        "\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}%\")"
      ],
      "metadata": {
        "id": "bIYPxuFxwzPE"
      },
      "id": "bIYPxuFxwzPE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment 2\n",
        "\n",
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "TlGnuXkaYQiq"
      },
      "id": "TlGnuXkaYQiq"
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining a new classification layer\n",
        "\n",
        "def build_model(fine_tune = False):\n",
        "    model = VivitForVideoClassification.from_pretrained(\"google/vivit-b-16x2-kinetics400\")\n",
        "    if fine_tune:\n",
        "        print('[INFO]: Fine-tuning all layers...')\n",
        "        for params in model.parameters():\n",
        "            params.requires_grad = True\n",
        "    if not fine_tune:\n",
        "        print('[INFO]: Freezing hidden layers...')\n",
        "        for params in model.parameters():\n",
        "            params.requires_grad = False\n",
        "\n",
        "    # Modify the model head for fine-tuning\n",
        "    num_features = model.classifier.in_features\n",
        "\n",
        "    # Additional linear layer and dropout layer\n",
        "    model.classifier = nn.Sequential(\n",
        "        nn.Linear(num_features, 256),  # Additional linear layer with 256 output features\n",
        "        nn.ReLU(inplace=True),         # Activation function (you can choose other activation functions too)\n",
        "        nn.Dropout(0.5),               # Dropout layer with 50% probability\n",
        "        nn.Linear(256, num_classes)    # Final prediction fc layer\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "kka_model = build_model(False)\n",
        "print(kka_model)"
      ],
      "metadata": {
        "id": "JhGolsz3aXZd"
      },
      "id": "JhGolsz3aXZd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verifying which parameters are frozen\n",
        "\n",
        "cnt = 1\n",
        "\n",
        "for name, param in kka_model.named_parameters():\n",
        "\n",
        "    print(f'{cnt}: {name}: {\"Trainable\" if param.requires_grad else \"Frozen\"}')\n",
        "\n",
        "    cnt+=1"
      ],
      "metadata": {
        "id": "iXEruWcDaqqP"
      },
      "id": "iXEruWcDaqqP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_accuracy_epoch = []\n",
        "train_loss_epoch = []\n",
        "\n",
        "val_accuracy_epoch = []\n",
        "val_loss_epoch = []"
      ],
      "metadata": {
        "id": "kjDREccFgEB7"
      },
      "execution_count": null,
      "outputs": [],
      "id": "kjDREccFgEB7"
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize Variables for EarlyStopping\n",
        "best_loss = float('inf')\n",
        "best_model_weights = None\n",
        "patience = 3\n",
        "\n",
        "optimizer = optim.Adam(kka_model.parameters(), lr=0.0001)\n",
        "\n",
        "my_lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
        "                                                             patience = patience)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "num_epochs = 20\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(device)\n",
        "kka_model.to(device)\n",
        "\n",
        "train_accuracy_epoch = []\n",
        "train_loss_epoch = []\n",
        "\n",
        "val_accuracy_epoch = []\n",
        "val_loss_epoch = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    train_running_loss = 0.0\n",
        "    train_running_correct = 0\n",
        "    train_bs_accumuator = 0\n",
        "\n",
        "    valid_running_loss = 0.0\n",
        "    valid_running_correct = 0\n",
        "    valid_bs_accumuator = 0\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    kka_model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    # Training Loop\n",
        "    for videos, labels in tqdm(trainloader):\n",
        "\n",
        "        videos, labels = videos.to(device), labels.to(device)\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = kka_model(videos)\n",
        "\n",
        "        logits = outputs.logits\n",
        "\n",
        "        train_bs_accumuator += logits.shape[0]\n",
        "\n",
        "        # Compute loss\n",
        "        loss = criterion(logits, labels)\n",
        "\n",
        "        # Calculate the accuracy.\n",
        "        _, preds = torch.max(logits, 1)\n",
        "\n",
        "        train_running_correct += (preds == labels).sum().item()\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * videos.size(0)\n",
        "\n",
        "    # Validation Loop\n",
        "    kka_model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for videos, labels in tqdm(validloader):\n",
        "\n",
        "            videos, labels = videos.to(device), labels.to(device)\n",
        "\n",
        "            outputs = kka_model(videos)\n",
        "\n",
        "            logits = outputs.logits\n",
        "\n",
        "            valid_bs_accumuator += logits.shape[0]\n",
        "\n",
        "            # Compute loss\n",
        "            loss = criterion(logits, labels)\n",
        "\n",
        "            _, preds = torch.max(logits, 1)\n",
        "\n",
        "            valid_running_correct += (preds == labels).sum().item()\n",
        "\n",
        "            valid_running_loss += loss.item() * videos.size(0)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    elapsed_time = end_time - start_time\n",
        "    print(f\"Elapsed time: {elapsed_time} seconds\")\n",
        "\n",
        "    epoch_loss = running_loss / len(trainloader.dataset)\n",
        "    epoch_acc = 100. * (train_running_correct / train_bs_accumuator)\n",
        "\n",
        "    valid_loss = valid_running_loss / len(validloader.dataset)\n",
        "    valid_acc = 100. * (valid_running_correct / valid_bs_accumuator)\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {epoch_loss:.4f}, Training Accuracy: {epoch_acc:.4f}\")\n",
        "\n",
        "    print(f\"Validation Loss: {valid_loss:.4f}, Validation Accuracy: {valid_acc:.4f}\")\n",
        "\n",
        "    train_accuracy_epoch.append(epoch_acc)\n",
        "    train_loss_epoch.append(epoch_loss)\n",
        "\n",
        "    val_accuracy_epoch.append(valid_acc)\n",
        "    val_loss_epoch.append(valid_loss)\n",
        "\n",
        "    my_lr_scheduler.step(valid_loss)\n",
        "\n",
        "    if valid_loss < best_loss:\n",
        "        best_loss = valid_loss\n",
        "        best_model_weights = copy.deepcopy(kka_model.state_dict())\n",
        "        patience = 3\n",
        "    else:\n",
        "        patience -= 1\n",
        "        if patience == 0:\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "kka_model.load_state_dict(best_model_weights)"
      ],
      "metadata": {
        "id": "lmIAQkA5gECA"
      },
      "execution_count": null,
      "outputs": [],
      "id": "lmIAQkA5gECA"
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the accuracy curve\n",
        "plt.plot(train_accuracy_epoch)\n",
        "plt.plot(val_accuracy_epoch)\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cHthDxtUgECD"
      },
      "execution_count": null,
      "outputs": [],
      "id": "cHthDxtUgECD"
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the loss curve\n",
        "plt.plot(train_loss_epoch)\n",
        "plt.plot(val_loss_epoch)\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "heCtYSzHgECD"
      },
      "execution_count": null,
      "outputs": [],
      "id": "heCtYSzHgECD"
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(kka_model, \"/content/drive/MyDrive/AI Masters final project/data_32_80_80_3_no_0/model_8_multi_layer_fc.pth\")"
      ],
      "metadata": {
        "id": "YyZrtfyjgECC"
      },
      "execution_count": null,
      "outputs": [],
      "id": "YyZrtfyjgECC"
    },
    {
      "cell_type": "code",
      "source": [
        "# Running the model on the test dataset\n",
        "kka_model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "test_running_correct = 0\n",
        "test_bs_accumuator = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in tqdm(testloader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = kka_model(images)\n",
        "\n",
        "        logits = outputs.logits\n",
        "        test_bs_accumuator += logits.shape[0]\n",
        "\n",
        "        _, preds = torch.max(logits, 1)\n",
        "        test_running_correct += (preds == labels).sum().item()\n",
        "\n",
        "test_accuracy = 100. * test_running_correct / test_bs_accumuator\n",
        "\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}%\")"
      ],
      "metadata": {
        "id": "mJfgCS6wyLKv"
      },
      "id": "mJfgCS6wyLKv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment 3\n",
        "\n",
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "ggd8KzZupsVu"
      },
      "id": "ggd8KzZupsVu"
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "zh3zg5rYpsVv"
      },
      "execution_count": null,
      "outputs": [],
      "id": "zh3zg5rYpsVv"
    },
    {
      "cell_type": "code",
      "source": [
        "train_accuracy_epoch = []\n",
        "train_loss_epoch = []\n",
        "\n",
        "val_accuracy_epoch = []\n",
        "val_loss_epoch = []"
      ],
      "metadata": {
        "id": "XNiBR_xrpsVv"
      },
      "execution_count": null,
      "outputs": [],
      "id": "XNiBR_xrpsVv"
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=0.00001)\n",
        "\n",
        "decayRate = 0.9\n",
        "my_lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=decayRate)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "num_epochs = 10\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(device)\n",
        "model.to(device)\n",
        "\n",
        "train_accuracy_epoch = []\n",
        "train_loss_epoch = []\n",
        "\n",
        "val_accuracy_epoch = []\n",
        "val_loss_epoch = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    train_running_loss = 0.0\n",
        "    train_running_correct = 0\n",
        "    train_bs_accumuator = 0\n",
        "\n",
        "    valid_running_loss = 0.0\n",
        "    valid_running_correct = 0\n",
        "    valid_bs_accumuator = 0\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    # Training Loop\n",
        "    for videos, labels in tqdm(trainloader):\n",
        "\n",
        "        videos, labels = videos.to(device), labels.to(device)\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(videos)\n",
        "\n",
        "        logits = outputs.logits\n",
        "\n",
        "        train_bs_accumuator += logits.shape[0]\n",
        "\n",
        "        # Compute loss\n",
        "        loss = criterion(logits, labels)\n",
        "\n",
        "        # Calculate the accuracy.\n",
        "        _, preds = torch.max(logits, 1)\n",
        "\n",
        "        train_running_correct += (preds == labels).sum().item()\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * videos.size(0)\n",
        "\n",
        "    # Validation Loop\n",
        "    with torch.no_grad():\n",
        "        for videos, labels in tqdm(validloader):\n",
        "\n",
        "            videos, labels = videos.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(videos)\n",
        "\n",
        "            logits = outputs.logits\n",
        "\n",
        "            valid_bs_accumuator += logits.shape[0]\n",
        "\n",
        "            # Compute loss\n",
        "            loss = criterion(logits, labels)\n",
        "\n",
        "            _, preds = torch.max(logits, 1)\n",
        "\n",
        "            valid_running_correct += (preds == labels).sum().item()\n",
        "\n",
        "            valid_running_loss += loss.item() * videos.size(0)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    elapsed_time = end_time - start_time\n",
        "    print(f\"Elapsed time: {elapsed_time} seconds\")\n",
        "\n",
        "    epoch_loss = running_loss / len(trainloader.dataset)\n",
        "    epoch_acc = 100. * (train_running_correct / train_bs_accumuator)\n",
        "\n",
        "    valid_loss = valid_running_loss / len(validloader.dataset)\n",
        "    valid_acc = 100. * (valid_running_correct / valid_bs_accumuator)\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {epoch_loss:.4f}, Training Accuracy: {epoch_acc:.4f}\")\n",
        "\n",
        "    print(f\"Validation Loss: {valid_loss:.4f}, Validation Accuracy: {valid_acc:.4f}\")\n",
        "\n",
        "    train_accuracy_epoch.append(epoch_acc)\n",
        "    train_loss_epoch.append(epoch_loss)\n",
        "\n",
        "    val_accuracy_epoch.append(valid_acc)\n",
        "    val_loss_epoch.append(valid_loss)\n",
        "\n",
        "    my_lr_scheduler.step()"
      ],
      "metadata": {
        "id": "6S6MrxoPpsVv"
      },
      "execution_count": null,
      "outputs": [],
      "id": "6S6MrxoPpsVv"
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the accuracy curve\n",
        "plt.plot(train_accuracy_epoch)\n",
        "plt.plot(val_accuracy_epoch)\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lepvUikXsf8c"
      },
      "execution_count": null,
      "outputs": [],
      "id": "lepvUikXsf8c"
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the loss curve\n",
        "plt.plot(train_loss_epoch)\n",
        "plt.plot(val_loss_epoch)\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kJzk3qKusf8l"
      },
      "execution_count": null,
      "outputs": [],
      "id": "kJzk3qKusf8l"
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, \"/content/drive/MyDrive/AI Masters final project/data_32_80_80_3_no_0/model_5.pth\")"
      ],
      "metadata": {
        "id": "ezRWukUHpsVw"
      },
      "execution_count": null,
      "outputs": [],
      "id": "ezRWukUHpsVw"
    },
    {
      "cell_type": "code",
      "source": [
        "# Running the model on the test dataset\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "test_running_correct = 0\n",
        "test_bs_accumuator = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in tqdm(testloader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "\n",
        "        logits = outputs.logits\n",
        "        test_bs_accumuator += logits.shape[0]\n",
        "\n",
        "        _, preds = torch.max(logits, 1)\n",
        "        test_running_correct += (preds == labels).sum().item()\n",
        "\n",
        "test_accuracy = 100. * test_running_correct / test_bs_accumuator\n",
        "\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}%\")"
      ],
      "metadata": {
        "id": "wSJQMZpPyTAy"
      },
      "id": "wSJQMZpPyTAy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment 4\n",
        "\n",
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "_eC45utZnHZ9"
      },
      "id": "_eC45utZnHZ9"
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "cNdpDI5iyfIN"
      },
      "id": "cNdpDI5iyfIN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_accuracy_epoch = []\n",
        "train_loss_epoch = []\n",
        "\n",
        "val_accuracy_epoch = []\n",
        "val_loss_epoch = []"
      ],
      "metadata": {
        "id": "uOffbt0YnGtZ"
      },
      "id": "uOffbt0YnGtZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "decayRate = 0.96\n",
        "my_lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=decayRate)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "num_epochs = 10\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(device)\n",
        "model.to(device)\n",
        "\n",
        "train_accuracy_epoch = []\n",
        "train_loss_epoch = []\n",
        "\n",
        "val_accuracy_epoch = []\n",
        "val_loss_epoch = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    train_running_loss = 0.0\n",
        "    train_running_correct = 0\n",
        "    train_bs_accumuator = 0\n",
        "\n",
        "    valid_running_loss = 0.0\n",
        "    valid_running_correct = 0\n",
        "    valid_bs_accumuator = 0\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    # Training Loop\n",
        "    for videos, labels in tqdm(trainloader):\n",
        "\n",
        "        videos, labels = videos.to(device), labels.to(device)\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(videos)\n",
        "\n",
        "        logits = outputs.logits\n",
        "\n",
        "        train_bs_accumuator += logits.shape[0]\n",
        "\n",
        "        # Compute loss\n",
        "        loss = criterion(logits, labels)\n",
        "\n",
        "        # Calculate the accuracy.\n",
        "        _, preds = torch.max(logits, 1)\n",
        "\n",
        "        train_running_correct += (preds == labels).sum().item()\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * videos.size(0)\n",
        "\n",
        "        i += 1\n",
        "\n",
        "    # Validation Loop\n",
        "    with torch.no_grad():\n",
        "        for videos, labels in validloader:\n",
        "\n",
        "            videos, labels = videos.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(videos)\n",
        "\n",
        "            logits = outputs.logits\n",
        "\n",
        "            valid_bs_accumuator += logits.shape[0]\n",
        "\n",
        "            # Compute loss\n",
        "            loss = criterion(logits, labels)\n",
        "\n",
        "            _, preds = torch.max(logits, 1)\n",
        "\n",
        "            valid_running_correct += (preds == labels).sum().item()\n",
        "\n",
        "            valid_running_loss += loss.item() * videos.size(0)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    elapsed_time = end_time - start_time\n",
        "    print(f\"Elapsed time: {elapsed_time} seconds\")\n",
        "\n",
        "    epoch_loss = running_loss / len(trainloader.dataset)\n",
        "    epoch_acc = 100. * (train_running_correct / train_bs_accumuator)\n",
        "\n",
        "    valid_loss = valid_running_loss / len(validloader.dataset)\n",
        "    valid_acc = 100. * (valid_running_correct / valid_bs_accumuator)\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {epoch_loss:.4f}, Training Accuracy: {epoch_acc:.4f}\")\n",
        "\n",
        "    print(f\"Validation Loss: {valid_loss:.4f}, Validation Accuracy: {valid_acc:.4f}\")\n",
        "\n",
        "    train_accuracy_epoch.append(epoch_acc)\n",
        "    train_loss_epoch.append(epoch_loss)\n",
        "\n",
        "    val_accuracy_epoch.append(valid_acc)\n",
        "    val_loss_epoch.append(valid_loss)\n",
        "\n",
        "    my_lr_scheduler.step()"
      ],
      "metadata": {
        "id": "V3MOoTKanTPH"
      },
      "id": "V3MOoTKanTPH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the accuracy curve\n",
        "plt.plot(train_accuracy_epoch)\n",
        "plt.plot(val_accuracy_epoch)\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OrzOwLKltysi"
      },
      "execution_count": null,
      "outputs": [],
      "id": "OrzOwLKltysi"
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the loss curve\n",
        "plt.plot(train_loss_epoch)\n",
        "plt.plot(val_loss_epoch)\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MNf_QXBTtyss"
      },
      "execution_count": null,
      "outputs": [],
      "id": "MNf_QXBTtyss"
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, \"/content/drive/MyDrive/AI Masters final project/data_32_80_80_3_no_0/model_4.pth\")"
      ],
      "metadata": {
        "id": "DDk4eoN9nZO2"
      },
      "id": "DDk4eoN9nZO2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Running the model on the test dataset\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "test_running_correct = 0\n",
        "test_bs_accumuator = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in tqdm(testloader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "\n",
        "        logits = outputs.logits\n",
        "        test_bs_accumuator += logits.shape[0]\n",
        "\n",
        "        _, preds = torch.max(logits, 1)\n",
        "        test_running_correct += (preds == labels).sum().item()\n",
        "\n",
        "test_accuracy = 100. * test_running_correct / test_bs_accumuator\n",
        "\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}%\")"
      ],
      "metadata": {
        "id": "hh9t3xCByWVI"
      },
      "id": "hh9t3xCByWVI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment 5\n",
        "\n",
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "jRcAQIhmXbKH"
      },
      "id": "jRcAQIhmXbKH"
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "TqxXUqb8ygnP"
      },
      "id": "TqxXUqb8ygnP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_accuracy_epoch = []\n",
        "train_loss_epoch = []\n",
        "\n",
        "val_accuracy_epoch = []\n",
        "val_loss_epoch = []"
      ],
      "metadata": {
        "id": "Xvv4K_wJUWXH"
      },
      "id": "Xvv4K_wJUWXH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "decayRate = 0.96\n",
        "my_lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=decayRate)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(device)\n",
        "model.to(device)\n",
        "\n",
        "train_accuracy_epoch = []\n",
        "train_loss_epoch = []\n",
        "\n",
        "val_accuracy_epoch = []\n",
        "val_loss_epoch = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    train_running_loss = 0.0\n",
        "    train_running_correct = 0\n",
        "    train_bs_accumuator = 0\n",
        "\n",
        "    valid_running_loss = 0.0\n",
        "    valid_running_correct = 0\n",
        "    valid_bs_accumuator = 0\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    # Training Loop\n",
        "    for videos, labels in tqdm(trainloader):\n",
        "\n",
        "        videos, labels = videos.to(device), labels.to(device)\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(videos)\n",
        "\n",
        "        logits = outputs.logits\n",
        "\n",
        "        train_bs_accumuator += logits.shape[0]\n",
        "\n",
        "        # Compute loss\n",
        "        loss = criterion(logits, labels)\n",
        "\n",
        "        # Calculate the accuracy.\n",
        "        _, preds = torch.max(logits, 1)\n",
        "\n",
        "        train_running_correct += (preds == labels).sum().item()\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * videos.size(0)\n",
        "\n",
        "    # Validation Loop\n",
        "    with torch.no_grad():\n",
        "        for videos, labels in validloader:\n",
        "\n",
        "            videos, labels = videos.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(videos)\n",
        "\n",
        "            logits = outputs.logits\n",
        "\n",
        "            valid_bs_accumuator += logits.shape[0]\n",
        "\n",
        "            # Compute loss\n",
        "            loss = criterion(logits, labels)\n",
        "\n",
        "            _, preds = torch.max(logits, 1)\n",
        "\n",
        "            valid_running_correct += (preds == labels).sum().item()\n",
        "\n",
        "            valid_running_loss += loss.item() * videos.size(0)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    elapsed_time = end_time - start_time\n",
        "    print(f\"Elapsed time: {elapsed_time} seconds\")\n",
        "\n",
        "    epoch_loss = running_loss / len(trainloader.dataset)\n",
        "    epoch_acc = 100. * (train_running_correct / train_bs_accumuator)\n",
        "\n",
        "    valid_loss = valid_running_loss / len(validloader.dataset)\n",
        "    valid_acc = 100. * (valid_running_correct / valid_bs_accumuator)\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {epoch_loss:.4f}, Training Accuracy: {epoch_acc:.4f}\")\n",
        "\n",
        "    print(f\"Validation Loss: {valid_loss:.4f}, Validation Accuracy: {valid_acc:.4f}\")\n",
        "\n",
        "    train_accuracy_epoch.append(epoch_acc)\n",
        "    train_loss_epoch.append(epoch_loss)\n",
        "\n",
        "    val_accuracy_epoch.append(valid_acc)\n",
        "    val_loss_epoch.append(valid_loss)\n",
        "\n",
        "    my_lr_scheduler.step()"
      ],
      "metadata": {
        "id": "tOvn3MeITcy6"
      },
      "id": "tOvn3MeITcy6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the accuracy curve\n",
        "plt.plot(train_accuracy_epoch)\n",
        "plt.plot(val_accuracy_epoch)\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t2UqjwwTu3c8"
      },
      "execution_count": null,
      "outputs": [],
      "id": "t2UqjwwTu3c8"
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the loss curve\n",
        "plt.plot(train_loss_epoch)\n",
        "plt.plot(val_loss_epoch)\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZarJY4zJu3dF"
      },
      "execution_count": null,
      "outputs": [],
      "id": "ZarJY4zJu3dF"
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, \"/content/drive/MyDrive/AI Masters final project/data_32_80_80_3_no_0/model_3.pth\")"
      ],
      "metadata": {
        "id": "umRf2RqXWgiR"
      },
      "id": "umRf2RqXWgiR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Running the model on the test dataset\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "test_running_correct = 0\n",
        "test_bs_accumuator = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in tqdm(testloader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "\n",
        "        logits = outputs.logits\n",
        "        test_bs_accumuator += logits.shape[0]\n",
        "\n",
        "        _, preds = torch.max(logits, 1)\n",
        "        test_running_correct += (preds == labels).sum().item()\n",
        "\n",
        "test_accuracy = 100. * test_running_correct / test_bs_accumuator\n",
        "\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}%\")"
      ],
      "metadata": {
        "id": "FUOCtlIlyYPe"
      },
      "id": "FUOCtlIlyYPe",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "machine_shape": "hm",
      "collapsed_sections": [
        "GmbhggzvMg9i",
        "tZU1rTii2i-6",
        "UrmeGnspNLdg",
        "g-n1USdo-q7N",
        "TlGnuXkaYQiq",
        "ggd8KzZupsVu",
        "jRcAQIhmXbKH"
      ]
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}